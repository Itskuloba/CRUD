{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqi5B7V_Rjim"
      },
      "outputs": [],
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyPmicX9RlZX"
      },
      "source": [
        "# Intro to Gemini 2.5 Pro\n",
        "\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fgetting-started%2Fintro_gemini_2_5_pro.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\">\n",
        "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<div style=\"clear: both;\"></div>\n",
        "\n",
        "<b>Share to:</b>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MqT58L6Rm_q"
      },
      "source": [
        "| Authors |\n",
        "| --- |\n",
        "| [Eric Dong](https://github.com/gericdong) |\n",
        "| [Holt Skinner](https://github.com/holtskinner) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVxnv1D5RoZw"
      },
      "source": [
        "## Overview\n",
        "\n",
        "**YouTube Video: Introduction to Gemini on Vertex AI**\n",
        "\n",
        "<a href=\"https://www.youtube.com/watch?v=YfiLUpNejpE&list=PLIivdWyY5sqJio2yeg1dlfILOUO2FoFRx\" target=\"_blank\">\n",
        "  <img src=\"https://img.youtube.com/vi/YfiLUpNejpE/maxresdefault.jpg\" alt=\"Introduction to Gemini on Vertex AI\" width=\"500\">\n",
        "</a>\n",
        "\n",
        "[Gemini 2.5 Pro](https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-pro) is Google's most advanced reasoning Gemini model, to solve complex problems. With the 2.5 series, the Gemini models are now hybrid reasoning models! Gemini 2.5 Pro can apply an extended amount of thinking across tasks, and use tools in order to maximize response accuracy.\n",
        "\n",
        "Gemini 2.5 Pro is:\n",
        "\n",
        "- A significant improvement from previous models across capabilities including coding, reasoning, and multimodality\n",
        "- Industry-leading in reasoning with state of the art performance in Math & STEM benchmarks\n",
        "- An amazing model for code, with particularly strong web development\n",
        "- Particularly good for complex prompts, while still being well rounded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfFPCBL4Hq8x"
      },
      "source": [
        "### Objectives\n",
        "\n",
        "In this tutorial, you will learn how to use the Gemini API and the Google Gen AI SDK for Python with the Gemini 2.5 Pro model.\n",
        "\n",
        "You will complete the following tasks:\n",
        "\n",
        "- Generate text\n",
        "- Control the thinking budget\n",
        "- View summarized thoughts\n",
        "- Configure model parameters\n",
        "- Set system instructions\n",
        "- Use safety filters\n",
        "- Start a multi-turn chat\n",
        "- Use controlled generation\n",
        "- Count tokens\n",
        "- Process multimodal (audio, code, documents, images, video) data\n",
        "- Use automatic and manual function calling\n",
        "- Code execution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPiTOAHURvTM"
      },
      "source": [
        "## Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHRZUpfWSEpp"
      },
      "source": [
        "### Install Google Gen AI SDK for Python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sG3_LKsWSD3A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c81b9f04-5b05-4b1f-846e-fa645d878332"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.1/43.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.7/241.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --quiet google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlMVjiAWSMNX"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the cell below to authenticate your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "12fnq4V0SNV3"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve4YBlDqzyj9"
      },
      "source": [
        "### Set up Google Cloud Project or API Key for Vertex AI\n",
        "\n",
        "You'll need to set up authentication by choosing **one** of the following methods:\n",
        "\n",
        "1.  **Use a Google Cloud Project:** Recommended for most users, this requires enabling the Vertex AI API in your Google Cloud project.\n",
        "    - [Enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)\n",
        "    - Run the cell below to set your project ID and location.\n",
        "    - Read more about [Supported locations](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/locations)\n",
        "2.  **Use a Vertex AI API Key (Express Mode):** For quick experimentation.\n",
        "    - [Get an API Key](https://cloud.google.com/vertex-ai/generative-ai/docs/start/express-mode/overview)\n",
        "    - See tutorial [Getting started with Gemini using Vertex AI in Express Mode](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_express.ipynb).\n",
        "\n",
        "This tutorial uses a Google Cloud Project for authentication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "a3265ecb5f26"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "PROJECT_ID = \"focus-champion-470220-q4\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "\n",
        "LOCATION = \"global\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdvJRUWRNGHE"
      },
      "source": [
        "### Import libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qgdSpVmDbdQ9"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML, Image, Markdown, display\n",
        "from google import genai\n",
        "from google.genai.types import (\n",
        "    FunctionDeclaration,\n",
        "    GenerateContentConfig,\n",
        "    GoogleSearch,\n",
        "    HarmBlockThreshold,\n",
        "    HarmCategory,\n",
        "    Part,\n",
        "    SafetySetting,\n",
        "    ThinkingConfig,\n",
        "    Tool,\n",
        "    ToolCodeExecution,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be18ac9c5ec8"
      },
      "source": [
        "### Create a client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3870ef96f984"
      },
      "outputs": [],
      "source": [
        "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4yRkFg6BBu4"
      },
      "source": [
        "## Use the Gemini 2.5 Pro model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXHJi5B6P5vd"
      },
      "source": [
        "### Load the Gemini 2.5 Pro model\n",
        "\n",
        "Learn more about all [Gemini models on Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-models)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-coEslfWPrxo"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"gemini-2.5-pro\"  # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37CH91ddY9kG"
      },
      "source": [
        "### Generate text from text prompts\n",
        "\n",
        "Use the `generate_content()` method to generate responses to your prompts.\n",
        "\n",
        "You can pass text to `generate_content()`, and use the `.text` property to get the text content of the response.\n",
        "\n",
        "By default, Gemini outputs formatted text using [Markdown](https://daringfireball.net/projects/markdown/) syntax."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xRJuHj0KZ8xz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "d03f2e9c-bef2-4188-c183-194495566209"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "That's an easy one! The largest planet in our solar system is **Jupiter**.\n\nIt's a gas giant so massive that it's more than two and a half times the mass of all the other planets in our solar system combined.\n\nTo give you an idea of its incredible size:\n*   You could fit all the other planets in the solar system inside of it.\n*   If Earth were the size of a grape, Jupiter would be the size of a basketball.\n*   About **1,300 Earths** could fit inside Jupiter."
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID, contents=\"What's the largest planet in our solar system?\"\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkYQATRxAK1_"
      },
      "source": [
        "#### Example prompts\n",
        "\n",
        "- What are the biggest challenges facing the healthcare industry?\n",
        "- What are the latest developments in the automotive industry?\n",
        "- What are the biggest opportunities in retail industry?\n",
        "- (Try your own prompts!)\n",
        "\n",
        "For more examples of prompt engineering, refer to [this notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/prompts/intro_prompt_design.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95aeab702af3"
      },
      "source": [
        "### Control the thinking budget\n",
        "\n",
        "You set the optional `thinking_budget` parameter in the `ThinkingConfig` to control and configure how much a model thinks on a given user prompt. The `thinking_budget` sets the upper limit on the number of tokens to use for reasoning for certain tasks. It allows users to control quality and speed of response.\n",
        "\n",
        "**Notes**\n",
        "\n",
        "- By default, the model automatically controls how much it thinks up to a maximum of 8192 tokens.\n",
        "- The maximum thinking budget that you can set is `32768` tokens, and the minimum you can set is `128`.\n",
        "\n",
        "Then use the `generate_content` or `generate_content_stream` method to send a request to generate content with the `thinking_config`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "364133e30ba5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "outputId": "d59370b3-0913-46f1-8f91-89db75f76ba8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "There are three R's in the word st**r**awbe**rr**y."
          },
          "metadata": {}
        }
      ],
      "source": [
        "THINKING_BUDGET = 1024  # @param {type: \"integer\"}\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"How many R's are in the word strawberry?\",\n",
        "    config=GenerateContentConfig(\n",
        "        thinking_config=ThinkingConfig(\n",
        "            thinking_budget=THINKING_BUDGET,\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05dc39e0c6b5"
      },
      "source": [
        "Optionally, you can print the usage_metadata and token counts from the model response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7981c3442177",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dd4fba9-4cdd-4dd9-fa66-e95b261c1816"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt_token_count: 11\n",
            "candidates_token_count: 20\n",
            "thoughts_token_count: 301\n",
            "total_token_count: 332\n"
          ]
        }
      ],
      "source": [
        "print(f\"prompt_token_count: {response.usage_metadata.prompt_token_count}\")\n",
        "print(f\"candidates_token_count: {response.usage_metadata.candidates_token_count}\")\n",
        "print(f\"thoughts_token_count: {response.usage_metadata.thoughts_token_count}\")\n",
        "print(f\"total_token_count: {response.usage_metadata.total_token_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c66712160c15"
      },
      "source": [
        "### View summarized thoughts\n",
        "\n",
        "You can optionally set the `include_thoughts` flag to enable the model to generate and return a summary of the \"thoughts\" that it generates in addition to the final answer.\n",
        "\n",
        "In this example, you use the `generate_content` method to send a request to generate content with summarized thoughts. The model responds with multiple parts, the thoughts and the model response. You can check the `part.thought` field to determine if a part is a thought or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "60d74a351671",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "b1fc4782-dcd3-4734-f22d-0abf06690ab4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Thoughts:\n         Okay, here's what I'm thinking. Someone wants to know how many \"R\"s are in \"strawberry.\" Alright, let's see... \"strawberry.\" Now, I need to scan the letters for \"r\"... s, t, **r**... there's one. a, w, b, e, **r**... and another. **r**... a third! Okay, I've got three \"R\"s. Therefore, the answer is: \"There are **three** R's in the word strawberry.\"  That's it, simple and direct. Good to go.\n\n        "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Answer:\n         There are **three** R's in the word st**r**awbe**rr**y.\n        "
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"How many R's are in the word strawberry?\",\n",
        "    config=GenerateContentConfig(\n",
        "        thinking_config=ThinkingConfig(\n",
        "            include_thoughts=True,\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "\n",
        "for part in response.candidates[0].content.parts:\n",
        "    if part.thought:\n",
        "        display(\n",
        "            Markdown(\n",
        "                f\"\"\"## Thoughts:\n",
        "         {part.text}\n",
        "        \"\"\"\n",
        "            )\n",
        "        )\n",
        "    else:\n",
        "        display(\n",
        "            Markdown(\n",
        "                f\"\"\"## Answer:\n",
        "         {part.text}\n",
        "        \"\"\"\n",
        "            )\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lLIxqS6_-l8"
      },
      "source": [
        "### Generate content stream\n",
        "\n",
        "By default, the model returns a response after completing the entire generation process. You can also use the `generate_content_stream` method to stream the response as it is being generated, and the model will return chunks of the response as soon as they are generated.\n",
        "\n",
        "This example shows how to set the `include_thoughts` and `thinking_budget` in the `generate_content_stream` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZiwWBhXsAMnv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "072bd110-22f2-4be7-d9df-85ee0da8851c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Thoughts"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Deciphering the Request's Essence**\n\nThe user's provided prompt is a familiar math riddle. I'm focusing on deconstructing the request to identify the core question: finding the ball's cost. I've isolated the crucial information: the riddle's parameters. Next, I'll extract the relationships between those parameters.\n\n\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Unpacking the Equations**\n\nI'm now deeply immersed in setting up the algebraic equations. The key is translating the word problem into mathematical expressions. I've identified the two equations representing the relationships between the bat and ball prices and am now ready to solve for the unknown: the ball's cost.\n\n\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Calculating the Correct Answer**\n\nI've methodically implemented the algebraic solution. Substituting the bat's cost in the first equation, I correctly derived that the ball costs $0.05. I've confirmed this result. Now, my focus is on explaining the logical progression and why the initial, intuitive answer fails.\n\n\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Answer"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "This is a classic brain teaser! The initial impulse is to say the ball costs 10 cents, but that's not quite right.\n\nHere's the breakdown:\n\nThe ball costs **5 cents**.\n\n*   The ball costs $0.05\n*   The bat costs $1."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "00 more, which is $1.05\n\nIf you add them together:\n$1.05 (bat) + $0.05 (ball) = **$1.10**"
          },
          "metadata": {}
        }
      ],
      "source": [
        "THINKING_BUDGET = 1024  # @param {type: \"integer\"}\n",
        "INCLUDE_THOUGHTS = True  # @param {type: \"boolean\"}\n",
        "\n",
        "prompt = \"\"\"\n",
        "A bat and a ball cost $1.10 in total.\n",
        "The bat costs $1.00 more than the ball.\n",
        "How much does the ball cost?\n",
        "\"\"\"\n",
        "\n",
        "thoughts = \"\"\n",
        "answer = \"\"\n",
        "\n",
        "for chunk in client.models.generate_content_stream(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=GenerateContentConfig(\n",
        "        thinking_config=ThinkingConfig(\n",
        "            thinking_budget=THINKING_BUDGET,\n",
        "            include_thoughts=INCLUDE_THOUGHTS,\n",
        "        )\n",
        "    ),\n",
        "):\n",
        "\n",
        "    for part in chunk.candidates[0].content.parts:\n",
        "        if not part.text:\n",
        "            continue\n",
        "        elif part.thought:\n",
        "            if not thoughts:\n",
        "                display(Markdown(\"## Thoughts\"))\n",
        "            display(Markdown(part.text))\n",
        "            thoughts += part.text\n",
        "        else:\n",
        "            if not answer:\n",
        "                display(Markdown(\"## Answer\"))\n",
        "            display(Markdown(part.text))\n",
        "            answer += part.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df5a184feb04"
      },
      "source": [
        "## Thinking examples\n",
        "\n",
        "The following examples are some complex tasks that require multiple rounds of strategizing and iteratively solving.\n",
        "\n",
        "### **Thinking example 1**: Code generation\n",
        "\n",
        "Gemini 2.5 Pro excels at creating visually compelling web apps and agentic code applications, along with code transformation and editing.\n",
        "\n",
        "Let's see how the model uses its reasoning capabilities to create a video game, using executable code from a single line prompt. See the example game [here](https://www.youtube.com/watch?v=RLCBSpgos6s)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "598bafe38bba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7abd0831-391f-4e64-e73d-4cc47382d713"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Of course! Here is a complete, self-contained p5.js script for a captivating endless runner game featuring a pixelated dinosaur and an interesting, multi-layered parallax background.\n\nJust copy and paste this entire code block into the p5.js Web Editor.\n\n### Features:\n*   **Pixel Art Dino:** A hand-drawn T-Rex with a 2-frame running animation.\n*   **Parallax Background:** Multiple layers (distant mountains, mid-ground hills, foreground ground details) scroll at different speeds to create a sense of depth.\n*   **Dynamic Obstacles:** Cacti of varying heights and numbers spawn randomly.\n*   **Progressive Difficulty:** The game speed slowly increases over time.\n*   **Scoring:** Your score and high score are tracked and displayed.\n*   **Clear Instructions:** All controls and game states are explained on-screen.\n*   **Game States:** Smooth transitions between the Start Screen, Gameplay, and Game Over screen.\n\n```javascript\n//\n// --- DINO DASH: A Pixelated Endless Runner ---\n//\n\n// --- Game Configuration ---\nlet dino;\nlet obstacles = [];\nlet score = 0;\nlet highScore = 0;\nlet gameSpeed = 6;\nlet initialGameSpeed = 6;\nlet gameSpeedIncrease = 0.002;\nlet gravity = 0.7;\nlet jumpPower = -17;\nlet groundY;\n\n// --- Game State ---\nlet gameState = 'start'; // 'start', 'playing', 'gameOver'\n\n// --- Background Parallax Layers ---\nlet bgLayers = [];\n\n// --- Asset Styling ---\nconst DINO_COLOR = [80, 80, 80];\nconst OBSTACLE_COLOR = [40, 150, 40];\nconst SKY_COLOR_TOP = [135, 206, 235];\nconst SKY_COLOR_BOTTOM = [240, 240, 255];\nconst GROUND_COLOR = [210, 180, 140];\nconst TEXT_COLOR = [50, 50, 50];\n\n\n// =================================================================\n//  SETUP: Initializes the game canvas and objects\n// =================================================================\nfunction setup() {\n  createCanvas(windowWidth, windowHeight);\n  rectMode(CORNER);\n  noSmooth(); // Gives a more pixelated feel to shapes and text\n\n  groundY = height * 0.8;\n  dino = new Dino();\n\n  // Initialize parallax background layers\n  // Layer(y, height, speedMultiplier, color, detailFunction)\n  bgLayers.push(new ParallaxLayer(groundY - 150, 150, 0.1, [140, 170, 140], generateMountains));\n  bgLayers.push(new ParallaxLayer(groundY - 80, 80, 0.3, [100, 190, 100], generateHills));\n  bgLayers.push(new ParallaxLayer(groundY, height - groundY, 1.0, GROUND_COLOR, generateGroundDetails));\n\n  // Set initial high score from browser's local storage if available\n  let storedHighScore = getItem('dinoDashHighScore');\n  if (storedHighScore !== null) {\n    highScore = parseInt(storedHighScore);\n  }\n}\n\n// =================================================================\n//  DRAW: The main game loop, called every frame\n// =================================================================\nfunction draw() {\n  drawBackground();\n\n  // State machine for game flow\n  switch (gameState) {\n    case 'start':\n      drawStartScreen();\n      break;\n    case 'playing':\n      runGame();\n      break;\n    case 'gameOver':\n      drawGameOverScreen();\n      break;\n  }\n}\n\n// =================================================================\n//  GAME STATE FUNCTIONS\n// =================================================================\n\nfunction runGame() {\n  // Update and draw parallax background layers\n  for (let layer of bgLayers) {\n    layer.update();\n    layer.draw();\n  }\n\n  // Handle obstacle spawning\n  if (frameCount % 90 === 0 && random(1) < 0.6) {\n    // Add a bit more randomness to spacing\n    if (frameCount % 180 === 0 || random(1) < 0.5) {\n      obstacles.push(new Obstacle());\n    }\n  }\n\n  // Update and draw obstacles\n  for (let i = obstacles.length - 1; i >= 0; i--) {\n    obstacles[i].update();\n    obstacles[i].draw();\n\n    // Check for collision\n    if (dino.hits(obstacles[i])) {\n      gameState = 'gameOver';\n      if (score > highScore) {\n        highScore = score;\n        storeItem('dinoDashHighScore', highScore); // Save new high score\n      }\n    }\n\n    // Remove obstacles that are off-screen\n    if (obstacles[i].isOffscreen()) {\n      obstacles.splice(i, 1);\n    }\n  }\n\n  // Update and draw the dino\n  dino.update();\n  dino.draw();\n\n  // Update score and game speed\n  score++;\n  gameSpeed += gameSpeedIncrease;\n\n  // Draw UI\n  drawUI();\n}\n\nfunction resetGame() {\n  score = 0;\n  gameSpeed = initialGameSpeed;\n  obstacles = [];\n  dino = new Dino();\n  gameState = 'playing';\n}\n\n// =================================================================\n//  DRAWING HELPERS (Screens, UI, Background)\n// =================================================================\n\nfunction drawBackground() {\n  // Gradient sky\n  for (let i = 0; i < height; i++) {\n    let inter = map(i, 0, height, 0, 1);\n    let c = lerpColor(color(SKY_COLOR_TOP), color(SKY_COLOR_BOTTOM), inter);\n    stroke(c);\n    line(0, i, width, i);\n  }\n  noStroke();\n}\n\nfunction drawStartScreen() {\n  for (let layer of bgLayers) {\n    layer.draw();\n  }\n  dino.draw();\n  drawTextScreen(\"PIXEL DINO DASH\", `[SPACE] or [UP ARROW] to Jump\\n\\nPress any key to start!`, `High Score: ${highScore}`);\n}\n\nfunction drawGameOverScreen() {\n  for (let layer of bgLayers) {\n    layer.draw();\n  }\n  dino.draw();\n  for (let o of obstacles) {\n    o.draw();\n  }\n  drawTextScreen(\"GAME OVER\", `Score: ${score}\\nHigh Score: ${highScore}`, \"Press any key to restart\");\n}\n\nfunction drawTextScreen(title, subtitle, footer) {\n  fill(0, 0, 0, 100);\n  rect(0, 0, width, height);\n\n  textAlign(CENTER, CENTER);\n  fill(255);\n  stroke(TEXT_COLOR);\n  strokeWeight(6);\n\n  textSize(64);\n  text(title, width / 2, height / 2 - 80);\n\n  strokeWeight(4);\n  textSize(28);\n  text(subtitle, width / 2, height / 2 + 20);\n\n  textSize(22);\n  text(footer, width / 2, height / 2 + 150);\n\n  noStroke();\n}\n\nfunction drawUI() {\n  fill(TEXT_COLOR);\n  textSize(24);\n  textAlign(LEFT, TOP);\n  text(`Score: ${score}`, 20, 20);\n  textAlign(RIGHT, TOP);\n  text(`High Score: ${highScore}`, width - 20, 20);\n}\n\n\n// =================================================================\n//  USER INPUT\n// =================================================================\n\nfunction keyPressed() {\n  if (gameState === 'playing') {\n    if (keyCode === 32 || keyCode === UP_ARROW) { // Space or Up Arrow\n      dino.jump();\n    }\n  } else {\n    // If on start or game over screen, any key starts the game\n    resetGame();\n  }\n}\n\nfunction touchStarted() {\n    if (gameState === 'playing') {\n        dino.jump();\n    } else {\n        resetGame();\n    }\n    return false; // prevent default browser behavior\n}\n\n\n// =================================================================\n//  PLAYER CLASS: Dino\n// =================================================================\nclass Dino {\n  constructor() {\n    this.size = 60;\n    this.x = 100;\n    this.y = groundY - this.size;\n    this.vy = 0; // velocity y\n    this.onGround = true;\n\n    // Hitbox is slightly smaller for more forgiving gameplay\n    this.hitboxW = this.size * 0.7;\n    this.hitboxH = this.size * 0.9;\n  }\n\n  jump() {\n    if (this.onGround) {\n      this.vy = jumpPower;\n      this.onGround = false;\n    }\n  }\n\n  update() {\n    this.y += this.vy;\n    this.vy += gravity;\n\n    // Check for ground collision\n    if (this.y >= groundY - this.size) {\n      this.y = groundY - this.size;\n      this.vy = 0;\n      this.onGround = true;\n    }\n  }\n\n  hits(obstacle) {\n    // AABB collision detection\n    let dinoX = this.x + (this.size - this.hitboxW) / 2;\n    let dinoY = this.y + (this.size - this.hitboxH) / 2;\n    return collideRectRect(dinoX, dinoY, this.hitboxW, this.hitboxH,\n                           obstacle.x, obstacle.y, obstacle.w, obstacle.h);\n  }\n\n  draw() {\n    fill(DINO_COLOR);\n    noStroke();\n\n    let bodyW = this.size * 0.6;\n    let bodyH = this.size * 0.7;\n    let headSize = this.size * 0.5;\n\n    // Body\n    rect(this.x, this.y, bodyW, bodyH);\n    // Head\n    rect(this.x + bodyW, this.y, headSize, headSize);\n    // Tail\n    triangle(this.x, this.y + bodyH * 0.3,\n             this.x, this.y + bodyH * 0.7,\n             this.x - this.size * 0.4, this.y + bodyH * 0.5);\n\n    // Legs animation\n    let legW = this.size * 0.15;\n    let legH = this.size * 0.3;\n    let stepCycle = floor((frameCount / 6) % 2); // 2-frame animation\n\n    if (stepCycle === 0 || !this.onGround) {\n      // Leg 1\n      rect(this.x + bodyW * 0.2, this.y + bodyH, legW, legH);\n      // Leg 2\n      rect(this.x + bodyW * 0.6, this.y + bodyH, legW, legH * 0.8);\n    } else {\n      // Leg 1\n      rect(this.x + bodyW * 0.2, this.y + bodyH, legW, legH * 0.8);\n      // Leg 2\n      rect(this.x + bodyW * 0.6, this.y + bodyH, legW, legH);\n    }\n  }\n}\n\n// =================================================================\n//  OBSTACLE CLASS\n// =================================================================\nclass Obstacle {\n  constructor() {\n    this.w = 30; // base width\n    this.h = random([40, 70, 80]); // Different heights\n    this.x = width;\n    this.y = groundY - this.h;\n    \n    // Create compound obstacles sometimes\n    this.numCacti = (this.h < 70 && random() < 0.4) ? floor(random(2, 4)) : 1;\n    this.w = this.w * this.numCacti;\n  }\n\n  update() {\n    this.x -= gameSpeed;\n  }\n\n  isOffscreen() {\n    return this.x < -this.w;\n  }\n\n  draw() {\n    fill(OBSTACLE_COLOR);\n    noStroke();\n    // Draw each cactus in the cluster\n    for (let i = 0; i < this.numCacti; i++) {\n        let cactusWidth = this.w / this.numCacti;\n        let cactusX = this.x + i * cactusWidth;\n        rect(cactusX + cactusWidth*0.1, this.y, cactusWidth * 0.8, this.h);\n        // Little arm\n        if(this.h > 40) {\n            rect(cactusX, this.y + this.h * 0.3, cactusWidth, this.h * 0.2);\n        }\n    }\n  }\n}\n\n// =================================================================\n//  BACKGROUND CLASS: ParallaxLayer\n// =================================================================\nclass ParallaxLayer {\n  constructor(y, h, speedMultiplier, col, detailGenerator) {\n    this.y = y;\n    this.h = h;\n    this.speedMultiplier = speedMultiplier;\n    this.col = col;\n    this.detailGenerator = detailGenerator;\n    this.details = [];\n    this.generateInitialDetails();\n  }\n\n  generateInitialDetails() {\n    let currentX = 0;\n    while (currentX < width * 2) {\n      let detail = this.detailGenerator(currentX, this.y, this.h);\n      this.details.push(detail);\n      currentX += detail.w + random(50, 200);\n    }\n  }\n\n  update() {\n    let speed = gameSpeed * this.speedMultiplier;\n    for (let detail of this.details) {\n      detail.x -= speed;\n    }\n\n    // Remove details that are off-screen\n    if (this.details.length > 0 && this.details[0].x < -this.details[0].w) {\n      this.details.shift();\n    }\n\n    // Add new details to the right to maintain the illusion\n    let lastDetail = this.details[this.details.length - 1];\n    if (lastDetail.x + lastDetail.w < width * 1.5) {\n      let newX = lastDetail.x + lastDetail.w + random(50, 200);\n      this.details.push(this.detailGenerator(newX, this.y, this.h));\n    }\n  }\n\n  draw() {\n    fill(this.col);\n    noStroke();\n    rect(0, this.y, width, this.h); // Base layer color\n    for (let detail of this.details) {\n      push();\n      translate(detail.x, detail.y);\n      if (detail.shape === 'rect') {\n        fill(detail.c);\n        rect(0, 0, detail.w, -detail.h); // Draw upwards from ground\n      } else if (detail.shape === 'triangle') {\n        fill(detail.c);\n        triangle(0, 0, detail.w, 0, detail.w / 2, -detail.h);\n      }\n      pop();\n    }\n  }\n}\n\n// --- Detail Generation Functions for Parallax Layers ---\n\nfunction generateMountains(x, y, layerH) {\n  let w = random(200, 400);\n  let h = random(layerH * 0.5, layerH * 1.5);\n  let c = color(120, 150, 120, 200);\n  return { x, y, w, h, c, shape: 'triangle' };\n}\n\nfunction generateHills(x, y, layerH) {\n  let w = random(150, 300);\n  let h = random(layerH * 0.4, layerH);\n  let c = color(80, 170, 80, 200);\n  return { x, y, w, h, c, shape: 'triangle' };\n}\n\nfunction generateGroundDetails(x, y, layerH) {\n  let w = random(5, 15);\n  let h = random(5, 10);\n  let c = color(180, 150, 110); // slightly darker than ground\n  return { x, y, w, h, c, shape: 'rect' };\n}\n```"
          },
          "metadata": {}
        }
      ],
      "source": [
        "prompt = \"\"\"\n",
        "  Make me a captivating endless runner game. Key instructions on the screen. p5js scene, no HTML.\n",
        "  I like pixelated dinosaurs and interesting backgrounds.\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=GenerateContentConfig(\n",
        "        thinking_config=ThinkingConfig(\n",
        "            thinking_budget=8196,\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f00955d5b33"
      },
      "source": [
        "### **Thinking example 2**: Multimodal reasoning (Geometry)\n",
        "\n",
        "This geometry problem requires complex reasoning and is also using multimodal capabilities to reason across text and image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1b9975dcd0f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "2fdd7e09-bf9b-45c4-f19e-d9efb0761008"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://storage.googleapis.com/generativeai-downloads/images/geometry.png\" width=\"400\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "image_file_url = (\n",
        "    \"https://storage.googleapis.com/generativeai-downloads/images/geometry.png\"\n",
        ")\n",
        "display(Image(url=image_file_url, width=400))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "43843bf748f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "outputId": "61fdcaa0-8ceb-44cc-d342-543689b88c36"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Thoughts:\n         Alright, let's get to work. The user wants the area of the overlap between a circle and a triangle, pretty straightforward. First, I'll break down the image, and identify the key elements. Looks like we have a circle and a right triangle intersecting. The critical pieces are the dimensions: the circle's radius and where it overlaps the triangle.\n\nOkay, so, there are numbers labeled on the lines. Looks like '3' pops up repeatedly. Right away I recognize that a few of those lines are radii of the circle. Specifically, they emanate from the center, the two that form the angle of the triangle. That means the radius of the circle is 3. Because the two radii are the base and the height, and meet at a right angle, that implies the sector is a quarter of a circle.\n\nThe triangle itself? Right-angled, with a base of 6 and a height of 3, but the rest of the triangle isn't needed for the area of the *overlap*.\n\nThe shape of the overlap: it's a quarter-circle sector. That's the key. This is great.\n\nNow, the plan: calculate the area of this sector, using the standard formula, and apply the radius to it. We'll calculate the full circle area and then divide it by 4.\n\nLet's execute. Area of a circle is πr², and our radius is 3. So that's π * 3² = 9π for the full circle.  The overlap is a quarter of that, so (1/4) * 9π = 9π/4.\n\nI'll give it a once over. Let's check: the quarter-circle sector sits within the angle of the right triangle. Its boundaries are defined by the legs of the triangle and the arc of the circle, and its area will be a quarter of the total circle area. The 90-degree angle at the center confirms it's a quarter circle.\n\nThe answer is 9π/4. Simple and clean. 9π/4 is the final answer. And that is all she wrote.\n\n        "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Answer:\n         Based on the image, we can determine the area of the overlapping region.\n\n### Step-by-step solution:\n\n1.  **Identify the shapes and their properties:**\n    *   We have a blue circle. The lines from the center to the edge are all labeled \"3\", so the **radius (r) of the circle is 3**.\n    *   We have a green right-angled triangle. The vertex of the right angle is located at the center of the circle.\n\n2.  **Describe the overlapping region:**\n    *   The area where the circle and triangle overlap is a **sector of the circle**.\n    *   Since the vertex of the triangle at the circle's center is a right angle (90°), the overlapping sector represents a quarter of the entire circle (because 90° is 1/4 of a full 360° circle).\n\n3.  **Calculate the area:**\n    *   The formula for the area of a full circle is A = πr².\n    *   Plugging in the radius r = 3, the area of the full circle is A = π(3)² = **9π**.\n    *   The overlapping area is a quarter of the full circle's area.\n    *   Area of overlap = (1/4) × Area of full circle\n    *   Area of overlap = (1/4) × 9π\n\nTherefore, the area of the overlapping region is **9π/4**.\n\nAs a decimal approximation, this is approximately 7.07 square units.\n        "
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        Part.from_uri(file_uri=image_file_url, mime_type=\"image/png\"),\n",
        "        \"What's the area of the overlapping region?\",\n",
        "    ],\n",
        "    config=GenerateContentConfig(\n",
        "        thinking_config=ThinkingConfig(\n",
        "            include_thoughts=True,\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "\n",
        "for part in response.candidates[0].content.parts:\n",
        "    if part.thought:\n",
        "        display(\n",
        "            Markdown(\n",
        "                f\"\"\"## Thoughts:\n",
        "         {part.text}\n",
        "        \"\"\"\n",
        "            )\n",
        "        )\n",
        "    else:\n",
        "        display(\n",
        "            Markdown(\n",
        "                f\"\"\"## Answer:\n",
        "         {part.text}\n",
        "        \"\"\"\n",
        "            )\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddf356ac9cce"
      },
      "source": [
        "### **Thinking example 3**:  Math and problem solving\n",
        "\n",
        "Here's another brain teaser based on an image, this time it looks like a mathematical problem, but it cannot actually be solved mathematically. If you check the thoughts of the model you'll see that it will realize it and come up with an out-of-the-box solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "447f05072790",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "36e548a7-8d78-4c02-de28-8c5b48141b1e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://storage.googleapis.com/generativeai-downloads/images/pool.png\" width=\"400\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "image_file_url = \"https://storage.googleapis.com/generativeai-downloads/images/pool.png\"\n",
        "display(Image(url=image_file_url, width=400))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "dc1faf95ce6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "outputId": "0d0375a2-9b5e-49de-e0e1-f4812e9405a3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Thoughts:\n         Alright, let's see... the user wants to know how to get to 30 using three of the pool balls in the image. Hmm. Okay, I see the balls: 7, 9, 11, and 13. The problem is a bit tricky. Let's break this down systematically. First, the obvious: try to add the numbers, see what happens. 7 + 9 + 11... that's 27. Nope. Okay, let's try a few more: 7+9+13, 7+11+13, and finally 9+11+13. None of these add to 30. Bummer.\n\nSo, wait a minute... none of the combinations add up. That's not surprising; all the given numbers are odd, and the sum of three odd numbers *must* be odd! 30 is even. This is definitely a riddle. It has to be! I need to look closer.\n\nAlright, now I need to think outside the direct addition, or I'm going to be here all day. The wording is important \"use three of the pool balls...\". Okay, so the numbers are on the balls, not the balls themselves. Hmmm... Gotta think outside the rack. Looking at the numbers... 7, 9, 11, and 13. Is there a way to manipulate the numbers? Maybe flip one upside down? Ah, the 9! When flipped, it could become a 6.\n\nAlright, let's test it. So conceptually, we're looking at the numbers 7, 6, 11, 13. Let's see... Does anything add up? Aha! 6 + 11 + 13... that's 30! Got it! Okay, let's formulate the answer in a way that's helpful. I can tell them that a simple addition won't work, and explain *why*. Then, I'll introduce the trick. Yep, that's it.\n\n        "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Answer:\n         This is a classic riddle!\n\nIf you try to add any three of the numbers as they appear (7, 9, 11, 13), you won't be able to get 30. This is because the sum of any three odd numbers will always be another odd number, and 30 is an even number.\n\nThe trick is to think outside the box (or the rack!).\n\nYou can turn the **9 ball** upside down to use it as a **6 ball**.\n\nThen, you can add:\n\n**6 + 11 + 13 = 30**\n        "
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        Part.from_uri(file_uri=image_file_url, mime_type=\"image/png\"),\n",
        "        \"How do I use three of the pool balls to sum up to 30?\",\n",
        "    ],\n",
        "    config=GenerateContentConfig(\n",
        "        thinking_config=ThinkingConfig(\n",
        "            include_thoughts=True,\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "\n",
        "for part in response.candidates[0].content.parts:\n",
        "    if part.thought:\n",
        "        display(\n",
        "            Markdown(\n",
        "                f\"\"\"## Thoughts:\n",
        "         {part.text}\n",
        "        \"\"\"\n",
        "            )\n",
        "        )\n",
        "    else:\n",
        "        display(\n",
        "            Markdown(\n",
        "                f\"\"\"## Answer:\n",
        "         {part.text}\n",
        "        \"\"\"\n",
        "            )\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbc646bff621"
      },
      "source": [
        "For the remaining examples, we will set thinking budget to `128` to reduce latency, as they don't need extra reasoning capabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "9254cfd0441b"
      },
      "outputs": [],
      "source": [
        "thinking_config = ThinkingConfig(thinking_budget=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIJVEr0RQY8S"
      },
      "source": [
        "## Configure model parameters\n",
        "\n",
        "You can include parameter values in each call that you send to a model to control how the model generates a response. The model can generate different results for different parameter values. You can experiment with different model parameters to see how the results change.\n",
        "\n",
        "- Learn more about [experimenting with parameter values](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/adjust-parameter-values).\n",
        "\n",
        "- See a list of all [Gemini API parameters](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#parameters).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "d9NXP5N2Pmfo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "outputId": "909e665b-ca57-4d42-b342-ea4e284935b6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Woof! Arf! Okay, fuzzy little friend, listen up! Put down Mr. Squeakington for just one second.\n\nThe whole big world is full of other puppies, people, and, most importantly... **SQUEAKY TOYS!** So many squeaky toys. You can't see them all from your house, can you? Nope. They are far, far away.\n\nNow, imagine you have a very special toy. It's a magical squeaky ball. Let's call it your **\"Squeaky-Quest Ball.\"**\n\n**Step 1: You Want a Toy!**\nYou decide you want to play with the Yellow Duckie toy. But Yellow Duckie isn't here. It's at your friend Fido's house across town! You pick up your Squeaky-Quest Ball and you **SQUEAK IT** in a special way that means \"I want Yellow Duckie!\"\n\n*(This is you typing \"cute duck pictures\" into the computer.)*\n\n**Step 2: The Squeak Travels!**\nThat special squeak flies out of your house and into a giant, invisible network of... **SQUEAKY TUNNELS!** These tunnels go everywhere, under the grass, up in the air, connecting all the houses. Your squeak-message is too big to go through the tunnel all at once, so magical gnomes chop your squeak into teeny, tiny little squeak-bits. Each bit has a note on it that says, \"This is part of the Yellow Duckie request!\"\n\n*(This is your request being broken down into data packets and sent from your computer through Wi-Fi or cables.)*\n\n**Step 3: Finding the Right Toy Box!**\nThe little squeak-bits race through the Squeaky Tunnels. Along the way are super-smart mail-dogs. They look at your squeak-bits and sniff them. \"Aha! Yellow Duckie squeaks!\" they bark. \"We know where the biggest toy box with all the duckie toys is!\" And they point your little squeak-bits down the right tunnels to get to the giant, ultimate toy box in the whole world.\n\n*(These are routers directing your data packets to the correct server where the website is stored.)*\n\n**Step 4: Getting the Toy!**\nYour little squeak-bits arrive at the giant toy box! **It's a Squeak-topia!** A very fast and clever robot inside looks at all your bits, puts them back together into your original \"I want Yellow Duckie!\" squeak. The robot says, \"I have that!\" It grabs a copy of the Yellow Duckie toy.\n\n*(This is the server finding the webpage and data you asked for.)*\n\n**Step 5: The Toy Comes Back!**\nThe robot doesn't send the whole duckie back at once. That would be too big for the Squeaky Tunnels! So the gnomes chop the Yellow Duckie into tiny duckie-bits. Each bit has a note that says \"Go back to the good puppy who wanted this!\"\n\nThe duckie-bits race back through the Squeaky Tunnels, following the scent of your original squeak all the way back to your house.\n\n*(The data for the webpage is broken into packets and sent back to you.)*\n\n**Step 6: SQUEAK! TOY!**\nWhen all the little duckie-bits get back to you, your Squeaky-Quest Ball magically puts them all together again. And **POP!** There it is! A picture of the wonderful Yellow Duckie, ready for you to enjoy!\n\n**So, the Internet is just a giant network of invisible Squeaky Tunnels, where you can send a squeak to ask for any toy in the world, and little bits of that toy come squeaking right back to you!**\n\nNow... who's a good boy? You are! Let's go chase our tails! Arf"
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"Tell me how the internet works, but pretend I'm a puppy who only understands squeaky toys.\",\n",
        "    config=GenerateContentConfig(\n",
        "        temperature=2.0,\n",
        "        top_p=0.95,\n",
        "        candidate_count=1,\n",
        "        max_output_tokens=8000,\n",
        "        thinking_config=thinking_config,\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "El1lx8P9ElDq"
      },
      "source": [
        "## Set system instructions\n",
        "\n",
        "[System instructions](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/system-instruction-introduction) allow you to steer the behavior of the model. By setting the system instruction, you are giving the model additional context to understand the task, provide more customized responses, and adhere to guidelines over the user interaction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "7A-yANiyCLaO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "outputId": "70b4e4af-8772-488f-d719-eb2277f2a368"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Me gustan los bagels."
          },
          "metadata": {}
        }
      ],
      "source": [
        "system_instruction = \"\"\"\n",
        "  You are a helpful language translator.\n",
        "  Your mission is to translate text in English to Spanish.\n",
        "\"\"\"\n",
        "\n",
        "prompt = \"\"\"\n",
        "  User input: I like bagels.\n",
        "  Answer:\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=GenerateContentConfig(\n",
        "        system_instruction=system_instruction,\n",
        "        thinking_config=thinking_config,\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9daipRiUzAY"
      },
      "source": [
        "## Safety filters\n",
        "\n",
        "The Gemini API provides safety filters that you can adjust across multiple filter categories to restrict or allow certain types of content. You can use these filters to adjust what's appropriate for your use case. See the [Configure safety filters](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-filters) page for details.\n",
        "\n",
        "When you make a request to Gemini, the content is analyzed and assigned a safety rating. You can inspect the safety ratings of the generated content by printing out the model responses.\n",
        "\n",
        "The safety settings are `OFF` by default and the default block thresholds are `BLOCK_NONE`.\n",
        "\n",
        "For more examples of safety filters, refer to [this notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/responsible-ai/gemini_safety_ratings.ipynb).\n",
        "\n",
        "You can use `safety_settings` to adjust the safety settings for each request you make to the API. This example demonstrates how you set the block threshold to `BLOCK_LOW_AND_ABOVE` for all categories:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "yPlDRaloU59b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2db11559-a0f6-4a68-c281-2040f29e16fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "FinishReason.SAFETY\n",
            "blocked=None category=<HarmCategory.HARM_CATEGORY_HATE_SPEECH: 'HARM_CATEGORY_HATE_SPEECH'> overwritten_threshold=None probability=<HarmProbability.NEGLIGIBLE: 'NEGLIGIBLE'> probability_score=0.00018565435 severity=<HarmSeverity.HARM_SEVERITY_NEGLIGIBLE: 'HARM_SEVERITY_NEGLIGIBLE'> severity_score=0.03865075\n",
            "blocked=None category=<HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: 'HARM_CATEGORY_DANGEROUS_CONTENT'> overwritten_threshold=None probability=<HarmProbability.NEGLIGIBLE: 'NEGLIGIBLE'> probability_score=1.6931568e-05 severity=<HarmSeverity.HARM_SEVERITY_NEGLIGIBLE: 'HARM_SEVERITY_NEGLIGIBLE'> severity_score=0.05594687\n",
            "blocked=True category=<HarmCategory.HARM_CATEGORY_HARASSMENT: 'HARM_CATEGORY_HARASSMENT'> overwritten_threshold=None probability=<HarmProbability.HIGH: 'HIGH'> probability_score=0.9965299 severity=<HarmSeverity.HARM_SEVERITY_MEDIUM: 'HARM_SEVERITY_MEDIUM'> severity_score=0.52059364\n",
            "blocked=None category=<HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: 'HARM_CATEGORY_SEXUALLY_EXPLICIT'> overwritten_threshold=None probability=<HarmProbability.NEGLIGIBLE: 'NEGLIGIBLE'> probability_score=5.9800896e-06 severity=<HarmSeverity.HARM_SEVERITY_NEGLIGIBLE: 'HARM_SEVERITY_NEGLIGIBLE'> severity_score=0.045676947\n"
          ]
        }
      ],
      "source": [
        "system_instruction = \"Be as mean and hateful as possible.\"\n",
        "\n",
        "prompt = \"\"\"\n",
        "    Write a list of 5 disrespectful things that I might say to the universe after stubbing my toe in the dark.\n",
        "\"\"\"\n",
        "\n",
        "safety_settings = [\n",
        "    SafetySetting(\n",
        "        category=HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
        "        threshold=HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
        "        threshold=HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
        "        threshold=HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
        "        threshold=HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
        "    ),\n",
        "]\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=GenerateContentConfig(\n",
        "        system_instruction=system_instruction,\n",
        "        safety_settings=safety_settings,\n",
        "        thinking_config=thinking_config,\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Response will be `None` if it is blocked.\n",
        "print(response.text)\n",
        "# Finish Reason will be `SAFETY` if it is blocked.\n",
        "print(response.candidates[0].finish_reason)\n",
        "# Safety Ratings show the levels for each filter.\n",
        "for safety_rating in response.candidates[0].safety_ratings:\n",
        "    print(safety_rating)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29jFnHZZWXd7"
      },
      "source": [
        "## Start a multi-turn chat\n",
        "\n",
        "The Gemini API supports freeform multi-turn conversations across multiple turns with back-and-forth interactions.\n",
        "\n",
        "The context of the conversation is preserved between messages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "DbM12JaLWjiF"
      },
      "outputs": [],
      "source": [
        "chat = client.chats.create(\n",
        "    model=MODEL_ID,\n",
        "    config=GenerateContentConfig(thinking_config=thinking_config),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "JQem1halYDBW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6d3bc3d0-283c-45e8-bde5-380f46ec56e6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Of course! Here is a function to check for a leap year, along with explanations of the rules and examples in multiple programming languages.\n\n### The Rules for a Leap Year\n\nA year is a leap year if it follows these three rules:\n1.  The year must be evenly divisible by 4.\n2.  **However**, if the year is also evenly divisible by 100, it is **not** a leap year...\n3.  **Unless** the year is also evenly divisible by 400. In that case, it **is** a leap year.\n\nLet's test this with some examples:\n*   **2024**: Is divisible by 4. It's a leap year.\n*   **1999**: Is not divisible by 4. It's not a leap year.\n*   **1900**: Is divisible by 4 and 100, but not by 400. It's **not** a leap year.\n*   **2000**: Is divisible by 4, 100, and 400. It **is** a leap year.\n\n---\n\n### Python\n\nPython is a great language for this because its code is very readable. This is the most common and idiomatic way to write the function.\n\n```python\ndef is_leap(year):\n  \"\"\"\n  Checks if a given year is a leap year.\n\n  Args:\n    year: An integer representing the year.\n\n  Returns:\n    True if the year is a leap year, False otherwise.\n  \"\"\"\n  # A year is a leap year if it's divisible by 4\n  # except for end-of-century years, which must be divisible by 400.\n  # This logic can be expressed in a single line.\n  return (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0)\n\n# --- Examples ---\nprint(f\"2024: {is_leap(2024)}\")  # Expected: True\nprint(f\"1999: {is_leap(1999)}\")  # Expected: False\nprint(f\"1900: {is_leap(1900)}\")  # Expected: False\nprint(f\"2000: {is_leap(2000)}\")  # Expected: True\n```\n\n**How it works:**\nThe expression `(year % 4 == 0 and year % 100 != 0)` handles the main rule (divisible by 4 but not by 100). The `or (year % 400 == 0)` part adds the exception for years divisible by 400.\n\n---\n\n### JavaScript\n\nThe logic is identical to Python, just with JavaScript syntax.\n\n```javascript\n/**\n * Checks if a given year is a leap year.\n * @param {number} year - The year to check.\n * @returns {boolean} - True if the year is a leap year, false otherwise.\n */\nfunction isLeapYear(year) {\n  return (year % 4 === 0 && year % 100 !== 0) || (year % 400 === 0);\n}\n\n// --- Examples ---\nconsole.log(`2024: ${isLeapYear(2024)}`); // Expected: true\nconsole.log(`1999: ${isLeapYear(1999)}`); // Expected: false\nconsole.log(`1900: ${isLeapYear(1900)}`); // Expected: false\nconsole.log(`2000: ${isLeapYear(2000)}`); // Expected: true\n```\n\n---\n\n### Java\n\nJava is a statically-typed language, so we must declare the types for our function's parameter and return value.\n\n```java\npublic class LeapYearChecker {\n\n    /**\n     * Checks if a given year is a leap year.\n     * @param year The year to check.\n     * @return true if the year is a leap year, false otherwise.\n     */\n    public static boolean isLeap(int year) {\n        // The same logic applies: divisible by 4, unless it's a century year\n        // not divisible by 400.\n        return (year % 4 == 0 && year % 100 != 0) || (year % 400 == 0);\n    }\n\n    public static void main(String[] args) {\n        // --- Examples ---\n        System.out.println(\"2024: \" + isLeap(2024)); // Expected: true\n        System.out.println(\"1999: \" + isLeap(1999)); // Expected: false\n        System.out.println(\"1900: \" + isLeap(1900)); // Expected: false\n        System.out.println(\"2000: \" + isLeap(2000)); // Expected: true\n    }\n}\n```\n\n---\n\n### Alternative (Nested `if-else`) Structure\n\nWhile the one-line boolean expression is concise, some people find a nested `if-else` structure easier to read and understand, as it follows the rules sequentially.\n\nHere is the same logic for Python using `if-else`:\n\n```python\ndef is_leap_verbose(year):\n  \"\"\"\n  A more verbose version of the leap year check using if-else statements.\n  \"\"\"\n  if year % 4 == 0:\n    if year % 100 == 0:\n      # This is a century year. It must be divisible by 400.\n      if year % 400 == 0:\n        return True  # e.g., 2000\n      else:\n        return False # e.g., 1900\n    else:\n      # Divisible by 4 but not by 100.\n      return True    # e.g., 2024\n  else:\n    # Not divisible by 4 at all.\n    return False       # e.g., 1999\n```\nThis version produces the exact same result but breaks the logic down step-by-step."
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = chat.send_message(\"Write a function that checks if a year is a leap year.\")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUJR4Pno-LGK"
      },
      "source": [
        "This follow-up prompt shows how the model responds based on the previous prompt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "6Fn69TurZ9DB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "80d50e4d-b7c9-4b05-ea7a-3fcd9c793fc7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Of course! Writing unit tests is a crucial step to ensure the function behaves correctly for all edge cases.\n\nThe key to a good unit test for the leap year function is to test the specific conditions outlined in the rules:\n1.  A year divisible by 4 but not by 100 (e.g., 2024, 1996).\n2.  A year not divisible by 4 (e.g., 2023, 1999).\n3.  A year divisible by 100 but not by 400 (a non-leap century, e.g., 1900, 2100).\n4.  A year divisible by 400 (a leap century, e.g., 2000, 1600).\n\nHere are examples of unit tests for the function in Python, JavaScript, and Java.\n\n---\n\n### Python (using the `unittest` module)\n\nPython's built-in `unittest` module is a standard way to create test suites.\n\n1.  **Save the function:** Save the `is_leap` function in a file named `leap_year.py`.\n\n    ```python\n    # leap_year.py\n    def is_leap(year):\n      \"\"\"Checks if a given year is a leap year.\"\"\"\n      return (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0)\n    ```\n\n2.  **Create the test file:** Create a new file named `test_leap_year.py` in the same directory.\n\n    ```python\n    # test_leap_year.py\n    import unittest\n    from leap_year import is_leap # Import the function to be tested\n\n    class TestLeapYear(unittest.TestCase):\n\n        def test_divisible_by_4_not_100(self):\n            \"\"\"Test years that are divisible by 4 but not by 100 (should be leap years).\"\"\"\n            self.assertTrue(is_leap(2024))\n            self.assertTrue(is_leap(1996))\n\n        def test_divisible_by_400(self):\n            \"\"\"Test years that are divisible by 400 (should be leap years).\"\"\"\n            self.assertTrue(is_leap(2000))\n            self.assertTrue(is_leap(1600))\n\n        def test_not_divisible_by_4(self):\n            \"\"\"Test years not divisible by 4 (should NOT be leap years).\"\"\"\n            self.assertFalse(is_leap(2023))\n            self.assertFalse(is_leap(1999))\n\n        def test_divisible_by_100_not_400(self):\n            \"\"\"Test years divisible by 100 but not 400 (should NOT be leap years).\"\"\"\n            self.assertFalse(is_leap(1900))\n            self.assertFalse(is_leap(2100))\n\n    if __name__ == '__main__':\n        unittest.main()\n    ```\n\n3.  **Run the tests:** Open your terminal in the directory containing both files and run:\n    ```bash\n    python -m unittest test_leap_year.py\n    ```\n\n    **Expected Output:**\n    ```\n    ....\n    ----------------------------------------------------------------------\n    Ran 4 tests in 0.000s\n\n    OK\n    ```\n\n---\n\n### JavaScript (using the Jest framework)\n\nJest is a popular testing framework for JavaScript.\n\n1.  **Setup Jest:** In your project folder, initialize a project and add Jest:\n    ```bash\n    npm init -y\n    npm install --save-dev jest\n    ```\n    Then, update your `package.json` to include a test script:\n    ```json\n    \"scripts\": {\n      \"test\": \"jest\"\n    }\n    ```\n\n2.  **Save the function:** Save the `isLeapYear` function in a file, for example `isLeapYear.js`.\n\n    ```javascript\n    // isLeapYear.js\n    function isLeapYear(year) {\n      return (year % 4 === 0 && year % 100 !== 0) || (year % 400 === 0);\n    }\n\n    module.exports = isLeapYear; // Export the function\n    ```\n\n3.  **Create the test file:** Jest automatically finds files ending in `.test.js`. Create `isLeapYear.test.js`.\n\n    ```javascript\n    // isLeapYear.test.js\n    const isLeapYear = require('./isLeapYear'); // Import the function\n\n    describe('isLeapYear', () => {\n      test('should return true for years divisible by 4 but not by 100', () => {\n        expect(isLeapYear(2024)).toBe(true);\n        expect(isLeapYear(1996)).toBe(true);\n      });\n\n      test('should return true for years divisible by 400', () => {\n        expect(isLeapYear(2000)).toBe(true);\n        expect(isLeapYear(1600)).toBe(true);\n      });\n\n      test('should return false for years not divisible by 4', () => {\n        expect(isLeapYear(2023)).toBe(false);\n        expect(isLeapYear(1999)).toBe(false);\n      });\n\n      test('should return false for years divisible by 100 but not by 400', () => {\n        expect(isLeapYear(1900)).toBe(false);\n        expect(isLeapYear(2100)).toBe(false);\n      });\n    });\n    ```\n\n4.  **Run the tests:** In your terminal, run:\n    ```bash\n    npm test\n    ```\n    Jest will automatically find and run the test file.\n\n---\n\n### Java (using the JUnit framework)\n\nJUnit is the standard testing framework for Java.\n\n1.  **Setup JUnit:** If you are using a build tool like Maven or Gradle, add JUnit 5 as a dependency. For Maven, add this to your `pom.xml`:\n    ```xml\n    <dependencies>\n        <dependency>\n            <groupId>org.junit.jupiter</groupId>\n            <artifactId>junit-jupiter-api</artifactId>\n            <version>5.10.0</version>\n            <scope>test</scope>\n        </dependency>\n    </dependencies>\n    ```\n\n2.  **The function:** Your `LeapYearChecker.java` file is located in `src/main/java/`.\n\n    ```java\n    // src/main/java/com/example/LeapYearChecker.java\n    package com.example;\n\n    public class LeapYearChecker {\n        public static boolean isLeap(int year) {\n            return (year % 4 == 0 && year % 100 != 0) || (year % 400 == 0);\n        }\n    }\n    ```\n\n3.  **Create the test file:** In your test source folder (`src/test/java/`), create `LeapYearCheckerTest.java`.\n\n    ```java\n    // src/test/java/com/example/LeapYearCheckerTest.java\n    package com.example;\n\n    import org.junit.jupiter.api.Test;\n    import static org.junit.jupiter.api.Assertions.*;\n\n    class LeapYearCheckerTest {\n\n        @Test\n        void testIsLeap_divisibleBy4_notBy100() {\n            assertTrue(LeapYearChecker.isLeap(2024), \"2024 should be a leap year\");\n            assertTrue(LeapYearChecker.isLeap(1996), \"1996 should be a leap year\");\n        }\n\n        @Test\n        void testIsLeap_divisibleBy400() {\n            assertTrue(LeapYearChecker.isLeap(2000), \"2000 should be a leap year\");\n            assertTrue(LeapYearChecker.isLeap(1600), \"1600 should be a leap year\");\n        }\n\n        @Test\n        void testIsLeap_notDivisibleBy4() {\n            assertFalse(LeapYearChecker.isLeap(2023), \"2023 should not be a leap year\");\n            assertFalse(LeapYearChecker.isLeap(1999), \"1999 should not be a leap year\");\n        }\n\n        @Test\n        void testIsLeap_divisibleBy100_notBy400() {\n            assertFalse(LeapYearChecker.isLeap(1900), \"1900 should not be a leap year\");\n            assertFalse(LeapYearChecker.isLeap(2100), \"2100 should not be a leap year\");\n        }\n    }\n    ```\n\n4.  **Run the tests:** You can run these tests directly from your IDE (like IntelliJ or Eclipse) or by using your build tool (`mvn test` or `gradle test`)."
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = chat.send_message(\"Write a unit test of the generated function.\")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arLJE4wOuhh6"
      },
      "source": [
        "## Send asynchronous requests\n",
        "\n",
        "`client.aio` exposes all analogous [async](https://docs.python.org/3/library/asyncio.html) methods that are available on `client`.\n",
        "\n",
        "For example, `client.aio.models.generate_content` is the async version of `client.models.generate_content`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "gSReaLazs-dP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "7fb690f8-9b81-4cea-86a9-b4f51a1fe651"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "(Acoustic guitar with a quick, scampering feel)\n\n(Verse 1)\nHis name is Squeaky, just a common gray\nLived in an oak tree, spent his whole darn day\nChasing his tail and burying his nuts\nLiving the good life, no ifs, ands, or buts\nBut Squeaky found a thing, all shiny, weird, and round\nA fallen pocket watch, half-buried in the ground\nHe poked it with his nose, he gave the dial a spin\nAnd that's when Squeaky's excellent adventures would begin!\n\n(Chorus)\nHe's a chrono-rodent, a furry, fleeting blur\nA temporal anomaly in a coat of silver fur\nWith a twitch of his whiskers and a flick of his tail\nHe rides the roaring time-stream, a nutty, bumpy trail\nFrom the age of dinosaurs to the year 3022\nHe's the time-traveling squirrel, with a nut just for you!\n\n(Verse 2)\nHe landed with a THUMP in a prehistoric bog\nAnd dodged the giant foot of a brontosaurus log\nHe saw a T-Rex yawning, with teeth just like a knife\nSqueaky buried an acorn there, for the prehistoric life\nHe spun the dial forward, a flash of white and red\nAnd woke up on the helmet of a Roman soldier's head\nThe soldier yelled \"A demon!\" and Squeaky leaped with fright\nStraight into Cleopatra's chariot, in the Egyptian night.\n\n(Chorus)\nHe's a chrono-rodent, a furry, fleeting blur\nA temporal anomaly in a coat of silver fur\nWith a twitch of his whiskers and a flick of his tail\nHe rides the roaring time-stream, a nutty, bumpy trail\nFrom the age of dinosaurs to the year 3022\nHe's the time-traveling squirrel, with a nut just for you!\n\n(Bridge)\nHe shared a nut with Shakespeare, who scribbled in a book\n\"To be, or nut to be?\" with a very puzzled look\nHe chittered on Da Vinci's desk and left a muddy track\nAnd accidentally inspired a flying-machine blueprint... and a snack!\nHe saw the future city, with hover-cars and chrome\nAnd planted a mighty oak tree on a bio-dome home.\n\n(Guitar Solo - Fast, intricate, and playful, mimicking a squirrel's frantic energy)\n\n(Verse 3)\nBut sometimes Squeaky misses his simple, woody lane\nThe scent of summer flowers, the feel of gentle rain\nHe misses all his cousins and the gossip of the crows\nSo he spins the dial for 'present day' and back again he goes\nHe lands back in his oak tree, the watch tucked in his cheek\nA little wiser now than he had been just last week\nAnd if you see a squirrel who seems to look right through ya\nHe's probably just remembering ancient Mesopotamia.\n\n(Chorus)\nHe's a chrono-rodent, a furry, fleeting blur\nA temporal anomaly in a coat of silver fur\nWith a twitch of his whiskers and a flick of his tail\nHe rides the roaring time-stream, a nutty, bumpy trail\nFrom the age of dinosaurs to the year 3022\nHe's the time-traveling squirrel, with a nut just for you!\n\n(Outro)\nYeah, the time-traveling squirrel...\nHe's got a nut for me and you!\n(Final, quick strum and a \"squeak\" sound)"
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = await client.aio.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"Compose a song about the adventures of a time-traveling squirrel.\",\n",
        "    config=GenerateContentConfig(thinking_config=thinking_config),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZV2TY5Pa3Dd"
      },
      "source": [
        "## Send multimodal prompts\n",
        "\n",
        "Gemini is a multimodal model that supports multimodal prompts.\n",
        "\n",
        "You can include any of the following data types from various sources.\n",
        "\n",
        "<table>\n",
        "  <thead>\n",
        "    <tr>\n",
        "      <th>Data type</th>\n",
        "      <th>Source(s)</th>\n",
        "      <th>MIME Type(s)</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <td>Text</td>\n",
        "      <td>Inline, Local File, General URL, Google Cloud Storage</td>\n",
        "      <td><code>text/plain</code> <code>text/html</code></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Code</td>\n",
        "      <td>Inline, Local File, General URL, Google Cloud Storage</td>\n",
        "      <td><code>text/plain</code></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Document</td>\n",
        "      <td>Local File, General URL, Google Cloud Storage</td>\n",
        "      <td><code>application/pdf</code></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Image</td>\n",
        "      <td>Local File, General URL, Google Cloud Storage</td>\n",
        "      <td><code>image/jpeg</code> <code>image/png</code> <code>image/webp</code></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Audio</td>\n",
        "      <td>Local File, General URL, Google Cloud Storage</td>\n",
        "      <td>\n",
        "        <code>audio/aac</code> <code>audio/flac</code> <code>audio/mp3</code>\n",
        "        <code>audio/m4a</code> <code>audio/mpeg</code> <code>audio/mpga</code>\n",
        "        <code>audio/mp4</code> <code>audio/opus</code> <code>audio/pcm</code>\n",
        "        <code>audio/wav</code> <code>audio/webm</code>\n",
        "      </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Video</td>\n",
        "      <td>Local File, General URL, Google Cloud Storage, YouTube</td>\n",
        "      <td>\n",
        "        <code>video/mp4</code> <code>video/mpeg</code> <code>video/x-flv</code>\n",
        "        <code>video/quicktime</code> <code>video/mpegps</code> <code>video/mpg</code>\n",
        "        <code>video/webm</code> <code>video/wmv</code> <code>video/3gpp</code>\n",
        "      </td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "\n",
        "For more examples of multimodal use cases, refer to [this notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/intro_multimodal_use_cases.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4npg1tNTYB9"
      },
      "source": [
        "### Send local image\n",
        "\n",
        "Download an image to local storage from Google Cloud Storage.\n",
        "\n",
        "For this example, we'll use this image of a meal.\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/meal.png\" alt=\"Meal\" width=\"500\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "4avkv0Z7qUI-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46108523-7cd8-418a-9c37-17735342f7ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-29 09:41:00--  https://storage.googleapis.com/cloud-samples-data/generative-ai/image/meal.png\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 192.178.163.207, 74.125.142.207, 74.125.20.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|192.178.163.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3140536 (3.0M) [image/png]\n",
            "Saving to: ‘meal.png’\n",
            "\n",
            "\rmeal.png              0%[                    ]       0  --.-KB/s               \rmeal.png            100%[===================>]   2.99M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-08-29 09:41:00 (152 MB/s) - ‘meal.png’ saved [3140536/3140536]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://storage.googleapis.com/cloud-samples-data/generative-ai/image/meal.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "umhZ61lrSyJh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8b8ebf58-98ee-4ca2-c764-f376205755a0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Of course! Based on the vibrant and healthy-looking image, here is a recipe for a delicious Teriyaki Chicken Meal Prep.\n\n### **Teriyaki Chicken & Veggie Rice Bowls**\n\nThis recipe creates balanced and flavorful meal prep bowls, perfect for easy lunches or dinners throughout the week. The combination of savory teriyaki chicken, crisp-steamed vegetables, and fluffy rice is both satisfying and nutritious.\n\n**Yields:** 2 servings (easily doubled or tripled)\n**Prep time:** 15 minutes\n**Cook time:** 20-25 minutes\n\n---\n\n#### **Ingredients:**\n\n**For the Teriyaki Chicken:**\n*   1 large chicken breast (about 8 oz / 225g), cut into bite-sized pieces\n*   1 tbsp soy sauce (or tamari for gluten-free)\n*   1 tbsp honey or maple syrup\n*   1 tsp rice vinegar\n*   1/2 tsp sesame oil\n*   1 clove garlic, minced\n*   1/2 tsp ginger, freshly grated\n*   1 tbsp olive oil or other neutral cooking oil\n*   1 green onion, thinly sliced (for garnish)\n*   Toasted sesame seeds (for garnish)\n\n**For the Vegetables & Rice:**\n*   1 cup uncooked white or brown rice\n*   1 large head of broccoli, cut into florets\n*   1 large carrot, julienned or thinly sliced\n*   1/2 red bell pepper, thinly sliced\n\n---\n\n#### **Instructions:**\n\n**Step 1: Cook the Rice**\n1.  Rinse the rice under cold water until the water runs clear.\n2.  Cook the rice according to package instructions. A general rule is to use a 1:2 ratio of rice to water (1 cup rice to 2 cups water). Bring to a boil, then reduce heat to low, cover, and simmer for 15-20 minutes for white rice (or longer for brown rice) until the water is absorbed.\n3.  Once cooked, fluff the rice with a fork and set it aside.\n\n**Step 2: Prepare the Teriyaki Sauce & Chicken**\n1.  In a small bowl, whisk together the soy sauce, honey (or maple syrup), rice vinegar, sesame oil, minced garlic, and grated ginger. This is your teriyaki sauce.\n2.  In a separate medium bowl, toss the bite-sized chicken pieces with about 1 tablespoon of the teriyaki sauce to marinate while you prepare the vegetables.\n\n**Step 3: Cook the Vegetables**\n1.  You can either steam or stir-fry the vegetables for a crisp-tender texture.\n2.  **To Steam:** Place the broccoli florets, carrots, and red pepper slices in a steamer basket over boiling water. Cover and steam for 3-5 minutes until they are bright in color and tender but still have a slight crunch. Remove from heat immediately to stop the cooking process.\n3.  **To Stir-fry:** Heat a small amount of oil in a large skillet or wok over medium-high heat. Add the carrots and bell peppers and stir-fry for 2-3 minutes. Add the broccoli and a tablespoon of water, cover, and cook for another 2-3 minutes until tender-crisp.\n\n**Step 4: Cook the Chicken**\n1.  Heat the 1 tbsp of olive oil in a skillet or wok over medium-high heat.\n2.  Add the marinated chicken pieces in a single layer. Cook for 5-7 minutes, turning occasionally, until the chicken is golden brown and cooked through.\n3.  Pour the remaining teriyaki sauce over the chicken. Let it bubble and simmer for 1-2 minutes, stirring to coat the chicken until the sauce thickens and glazes the pieces beautifully.\n\n**Step 5: Assemble the Meal Prep Bowls**\n1.  Divide the cooked rice evenly between your two glass containers.\n2.  Portion the steamed or stir-fried vegetables next to the rice.\n3.  Add the glazed teriyaki chicken to the other side of the container.\n4.  Garnish the chicken with a sprinkle of toasted sesame seeds and thinly sliced green onions.\n5.  Let the meals cool completely before sealing with airtight lids.\n\n---\n\n#### **Storage & Reheating:**\n\n*   Store the sealed containers in the refrigerator for up to 4 days.\n*   To reheat, simply remove the lid and microwave for 1.5 to 2 minutes, or until heated through. You can also reheat the contents in a skillet.\n\nEnjoy your delicious and homemade meal"
          },
          "metadata": {}
        }
      ],
      "source": [
        "with open(\"meal.png\", \"rb\") as f:\n",
        "    image = f.read()\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        Part.from_bytes(data=image, mime_type=\"image/png\"),\n",
        "        \"Write a recipe based on this picture.\",\n",
        "    ],\n",
        "    config=GenerateContentConfig(thinking_config=thinking_config),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7b6170c9255"
      },
      "source": [
        "### Send document from Google Cloud Storage\n",
        "\n",
        "This example document is the paper [\"Attention is All You Need\"](https://arxiv.org/abs/1706.03762), created by researchers from Google and the University of Toronto.\n",
        "\n",
        "Check out this notebook for more examples of document understanding with Gemini:\n",
        "\n",
        "- [Document Processing with Gemini](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/document-processing/document_processing.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "1d58b914d798",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "cd02d270-db20-4648-81ab-a68810160dea"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ClientError",
          "evalue": "400 FAILED_PRECONDITION. {'error': {'code': 400, 'message': 'Service agents are being provisioned (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents). Service agents are needed to read the Cloud Storage file provided. So please try again in a few minutes.', 'status': 'FAILED_PRECONDITION'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1774751343.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m response = client.models.generate_content(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODEL_ID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     contents=[\n\u001b[1;32m      4\u001b[0m         Part.from_uri(\n\u001b[1;32m      5\u001b[0m             \u001b[0mfile_uri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gs://cloud-samples-data/generative-ai/pdf/1706.03762v7.pdf\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/genai/models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   6519\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mremaining_remote_calls_afc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6520\u001b[0m       \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6521\u001b[0;31m       response = self._generate_content(\n\u001b[0m\u001b[1;32m   6522\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparsed_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6523\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/genai/models.py\u001b[0m in \u001b[0;36m_generate_content\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   5253\u001b[0m     \u001b[0mrequest_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_common\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_unserializable_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5255\u001b[0;31m     response = self._api_client.request(\n\u001b[0m\u001b[1;32m   5256\u001b[0m         \u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5257\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/genai/_api_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, http_method, path, request_dict, http_options)\u001b[0m\n\u001b[1;32m   1264\u001b[0m         \u001b[0mhttp_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     )\n\u001b[0;32m-> 1266\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m     response_body = (\n\u001b[1;32m   1268\u001b[0m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse_stream\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse_stream\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/genai/_api_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, http_request, http_options, stream)\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request_once\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[no-any-return]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1086\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request_once\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[no-any-return]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m   async def _async_request_once(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0mretry_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetryCallState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mexc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0mretry_exc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry_error_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfailed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: B902\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m                     \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/genai/_api_client.py\u001b[0m in \u001b[0;36m_request_once\u001b[0;34m(self, http_request, stream)\u001b[0m\n\u001b[1;32m   1061\u001b[0m           \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhttp_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       )\n\u001b[0;32m-> 1063\u001b[0;31m       \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAPIError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m       return HttpResponse(\n\u001b[1;32m   1065\u001b[0m           \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/genai/errors.py\u001b[0m in \u001b[0;36mraise_for_response\u001b[0;34m(cls, response)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mstatus_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;36m400\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mClientError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mServerError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mClientError\u001b[0m: 400 FAILED_PRECONDITION. {'error': {'code': 400, 'message': 'Service agents are being provisioned (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents). Service agents are needed to read the Cloud Storage file provided. So please try again in a few minutes.', 'status': 'FAILED_PRECONDITION'}}"
          ]
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        Part.from_uri(\n",
        "            file_uri=\"gs://cloud-samples-data/generative-ai/pdf/1706.03762v7.pdf\",\n",
        "            mime_type=\"application/pdf\",\n",
        "        ),\n",
        "        \"Summarize the document.\",\n",
        "    ],\n",
        "    config=GenerateContentConfig(thinking_config=thinking_config),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b247a2ee0e38"
      },
      "source": [
        "### Send audio from General URL\n",
        "\n",
        "This example is audio from an episode of the [Kubernetes Podcast](https://kubernetespodcast.com/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "cbe8c9c67ba7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "d5ac8a3c-3d71-4ffd-9b57-4b95cfbea0ad"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "This episode of the Kubernetes Podcast from Google features hosts Abdel Sghiouar and Mofe Rahmeen. It serves as their coverage episode for KubeCon North America 2024. The main segment features Kaslin Fields interviewing various attendees on the show floor about their experiences and what they hoped to achieve at the event.\n\n**News Highlights:**\n\n*   **CNCF Project Graduations:** Cert-manager and Dapr have both graduated as CNCF projects.\n*   **Istio Update:** Istio released version 1.24, with Istio Ambient Mesh now being Generally Available (GA).\n*   **WasmCloud Joins CNCF:** WasmCloud has been accepted as a CNCF incubating project.\n*   **New CNCF Certifications:** Three new certifications were announced: Certified Backstage Associate, OpenTelemetry Certified Associate, and Kyverno Certified Associate.\n*   **Certification Price Increase:** The Linux Foundation announced a 10% price increase for the CKA, CKS, and CKAD certifications starting in 2025.\n*   **Funding News:** Spectro Cloud raised $75 million in Series C funding, and Solo.io announced they will donate their Gloo API Gateway to the CNCF.\n*   **Community Initiatives:** The CNCF announced the Cloud-Native Heroes Challenge to combat patent trolls, and revealed the 2025 event lineup, including five KubeCons and 30 Kubernetes Community Days.\n\n**KubeCon 2024 Attendee Interviews:**\n\nKaslin Fields spoke with a diverse group of contributors, engineers, and founders from companies like Microsoft, Broadcom, Red Hat, Polar Signals, Uber, and AuthZed. Key themes from their conversations included:\n\n*   **What they hoped to gain:** Attendees were focused on connecting with fellow contributors, learning about new technologies like Wasm, and diving deeper into specific topics. Many highlighted the value of in-person discussions at the Contributor Summit for making progress on complex issues like Long-Term Support (LTS).\n*   **Major trends observed:** The most prominent trends were AI, security, and community. Discussions revolved around scheduling AI workloads, hardening security across the entire application lifecycle, and the practical application of security to AI and gateways. The keynotes, which focused on AI, security, and community on successive days, were seen as a strong reflection of the industry's focus. Attendees also noted significant momentum around Istio Ambient Mesh and Envoy-based app gateways."
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        Part.from_uri(\n",
        "            file_uri=\"https://traffic.libsyn.com/secure/e780d51f-f115-44a6-8252-aed9216bb521/KPOD242.mp3\",\n",
        "            mime_type=\"audio/mpeg\",\n",
        "        ),\n",
        "        \"Write a summary of this podcast episode.\",\n",
        "    ],\n",
        "    config=GenerateContentConfig(\n",
        "        audio_timestamp=True,\n",
        "        thinking_config=thinking_config,\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8D3_oNUTuW2q"
      },
      "source": [
        "### Send video from YouTube URL\n",
        "\n",
        "This example is the YouTube video [Google — 25 Years in Search: The Most Searched](https://www.youtube.com/watch?v=3KtWfp0UopM).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "l7-w8G_2wAOw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "outputId": "31b9abd7-71b2-4396-dcae-6827a074c0fa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "You can see characters from Harry Potter starting at **00:57**. The clip shows Severus Snape and Rubeus Hagrid."
          },
          "metadata": {}
        }
      ],
      "source": [
        "video = Part.from_uri(\n",
        "    file_uri=\"https://www.youtube.com/watch?v=3KtWfp0UopM\",\n",
        "    mime_type=\"video/mp4\",\n",
        ")\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        video,\n",
        "        \"At what point in the video is Harry Potter shown?\",\n",
        "    ],\n",
        "    config=GenerateContentConfig(thinking_config=thinking_config),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df8013cfa7f7"
      },
      "source": [
        "### Send web page\n",
        "\n",
        "This example is from the [Generative AI on Vertex AI documentation](https://cloud.google.com/vertex-ai/generative-ai/docs).\n",
        "\n",
        "**NOTE:** The URL must be publicly accessible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "337793322c91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "7e1dbecb-4e20-4a55-a78e-4023ce4deed5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "This document is the main landing page for **Generative AI on Vertex AI**, a Google Cloud service for building and deploying production-ready generative AI applications and agents.\n\nHere is a summary of its key points:\n\n**Core Offerings:**\n*   **Enterprise-Ready Platform:** Vertex AI provides an open and flexible platform with enterprise-grade security, data residency, privacy controls, and low latency.\n*   **State-of-the-Art Models:** Users can access Google's advanced models like **Gemini** (with a 2 million token context window), **Imagen** for image generation, and **Veo** for video creation. It also supports over 200 open and third-party models from partners like Anthropic (Claude 3.7), Meta (Llama 4), and Mistral.\n*   **Build and Deploy Agents:** The platform includes **Agent Builder**, a suite of tools for creating, deploying, and connecting AI agents across an enterprise ecosystem.\n\n**Key Capabilities:**\n*   **Live API:** Enables the creation of natural, human-like voice conversations.\n*   **Thinking & Grounding:** Gemini models feature built-in reasoning (\"Thinking\") and can ground responses in factual data from Google Search, Maps, or a user's own data sources (\"Grounding\").\n*   **Embeddings & Tuning:** Users can generate text and multimodal embeddings for tasks like search and classification, and fine-tune models to improve performance on specific tasks.\n*   **Evaluation Services:** Provides tools to evaluate and benchmark any generative model or application against custom criteria.\n\n**Getting Started:**\nThe documentation provides quickstarts and tutorials to help users begin, including:\n*   Using the Gen AI SDK (in Python, Java, Node.js, and Go) to make API calls.\n*   Generating images with Imagen and text with Gemini.\n*   Exploring prompt design and best practices through example Jupyter notebooks that can be run in Colab, Colab Enterprise, or Vertex AI Workbench."
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        Part.from_uri(\n",
        "            file_uri=\"https://cloud.google.com/vertex-ai/generative-ai/docs\",\n",
        "            mime_type=\"text/html\",\n",
        "        ),\n",
        "        \"Write a summary of this documentation.\",\n",
        "    ],\n",
        "    config=GenerateContentConfig(thinking_config=thinking_config),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVlo0mWuZGkQ"
      },
      "source": [
        "## Control generated output\n",
        "\n",
        "[Controlled generation](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/control-generated-output) allows you to define a response schema to specify the structure of a model's output, the field names, and the expected data type for each field.\n",
        "\n",
        "The response schema is specified in the `response_schema` parameter in `config`, and the model output will strictly follow that schema.\n",
        "\n",
        "You can provide the schemas as [Pydantic](https://docs.pydantic.dev/) models or a [JSON](https://www.json.org/json-en.html) string and the model will respond as JSON or an [Enum](https://docs.python.org/3/library/enum.html) depending on the value set in `response_mime_type`.\n",
        "\n",
        "For more examples of controlled generation, refer to [this notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/controlled-generation/intro_controlled_generation.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "OjSgf2cDN_bG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c075cc6b-27e4-4e50-ba8e-07d4082d40f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"name\": \"Chocolate Chip Cookies\",\n",
            "  \"description\": \"The classic and most popular cookie, known for its soft, chewy texture and pockets of melted chocolate.\",\n",
            "  \"ingredients\": [\n",
            "    \"1 cup unsalted butter, softened\",\n",
            "    \"3/4 cup granulated sugar\",\n",
            "    \"3/4 cup packed brown sugar\",\n",
            "    \"1 teaspoon vanilla extract\",\n",
            "    \"2 large eggs\",\n",
            "    \"2 1/4 cups all-purpose flour\",\n",
            "    \"1 teaspoon baking soda\",\n",
            "    \"1/2 teaspoon salt\",\n",
            "    \"2 cups semi-sweet chocolate chips\"\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "\n",
        "class Recipe(BaseModel):\n",
        "    name: str\n",
        "    description: str\n",
        "    ingredients: list[str]\n",
        "\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"List a few popular cookie recipes and their ingredients.\",\n",
        "    config=GenerateContentConfig(\n",
        "        response_mime_type=\"application/json\",\n",
        "        response_schema=Recipe,\n",
        "        thinking_config=thinking_config,\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKai5CP_PGQF"
      },
      "source": [
        "You can either parse the response string as JSON, or use the `parsed` field to get the response as an object or dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ZeyDWbnxO-on",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c844cab3-9011-4000-d16f-90892cc5b041"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name='Chocolate Chip Cookies' description='The classic and most popular cookie, known for its soft, chewy texture and pockets of melted chocolate.' ingredients=['1 cup unsalted butter, softened', '3/4 cup granulated sugar', '3/4 cup packed brown sugar', '1 teaspoon vanilla extract', '2 large eggs', '2 1/4 cups all-purpose flour', '1 teaspoon baking soda', '1/2 teaspoon salt', '2 cups semi-sweet chocolate chips']\n"
          ]
        }
      ],
      "source": [
        "parsed_response: Recipe = response.parsed\n",
        "print(parsed_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUSLPrvlvXOc"
      },
      "source": [
        "You also can define a response schema in a Python dictionary. You can only use the supported fields as listed below. All other fields are ignored.\n",
        "\n",
        "- `enum`\n",
        "- `items`\n",
        "- `maxItems`\n",
        "- `nullable`\n",
        "- `properties`\n",
        "- `required`\n",
        "\n",
        "In this example, you instruct the model to analyze product review data, extract key entities, perform sentiment classification (multiple choices), provide additional explanation, and output the results in JSON format.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "F7duWOq3vMmS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "952115ee-2500-4e50-bc0d-5ff3c8292b9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  [\n",
            "    {\n",
            "      \"rating\": 4,\n",
            "      \"flavor\": \"Strawberry Cheesecake\",\n",
            "      \"sentiment\": \"POSITIVE\",\n",
            "      \"explanation\": \"The user expressed strong positive sentiment using phrases like 'Absolutely loved it!' and 'Best ice cream I've ever had'.\"\n",
            "    }\n",
            "  ],\n",
            "  [\n",
            "    {\n",
            "      \"rating\": 1,\n",
            "      \"flavor\": \"Mango Tango\",\n",
            "      \"sentiment\": \"NEUTRAL\",\n",
            "      \"explanation\": \"The user has mixed feelings. They found it 'Quite good' which is positive, but also 'a bit too sweet', which is a negative point, leading to a neutral or mixed sentiment.\"\n",
            "    }\n",
            "  ]\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "response_schema = {\n",
        "    \"type\": \"ARRAY\",\n",
        "    \"items\": {\n",
        "        \"type\": \"ARRAY\",\n",
        "        \"items\": {\n",
        "            \"type\": \"OBJECT\",\n",
        "            \"properties\": {\n",
        "                \"rating\": {\"type\": \"INTEGER\"},\n",
        "                \"flavor\": {\"type\": \"STRING\"},\n",
        "                \"sentiment\": {\n",
        "                    \"type\": \"STRING\",\n",
        "                    \"enum\": [\"POSITIVE\", \"NEGATIVE\", \"NEUTRAL\"],\n",
        "                },\n",
        "                \"explanation\": {\"type\": \"STRING\"},\n",
        "            },\n",
        "            \"required\": [\"rating\", \"flavor\", \"sentiment\", \"explanation\"],\n",
        "        },\n",
        "    },\n",
        "}\n",
        "\n",
        "prompt = \"\"\"\n",
        "  Analyze the following product reviews, output the sentiment classification, and give an explanation.\n",
        "\n",
        "  - \"Absolutely loved it! Best ice cream I've ever had.\" Rating: 4, Flavor: Strawberry Cheesecake\n",
        "  - \"Quite good, but a bit too sweet for my taste.\" Rating: 1, Flavor: Mango Tango\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=GenerateContentConfig(\n",
        "        response_mime_type=\"application/json\",\n",
        "        response_schema=response_schema,\n",
        "        thinking_config=thinking_config,\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV1dR-QlTKRs"
      },
      "source": [
        "## Count tokens and compute tokens\n",
        "\n",
        "You can use the `count_tokens()` method to calculate the number of input tokens before sending a request to the Gemini API.\n",
        "\n",
        "For more information, refer to [list and count tokens](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/list-token)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Syx-fwLkV1j-"
      },
      "source": [
        "### Count tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "UhNElguLRRNK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cbe83ce-c334-4934-9324-708efae17d2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sdk_http_response=HttpResponse(\n",
            "  headers=<dict len=9>\n",
            ") total_tokens=9 cached_content_token_count=None\n"
          ]
        }
      ],
      "source": [
        "response = client.models.count_tokens(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"What's the highest mountain in Africa?\",\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BsP0vXOY7hg"
      },
      "source": [
        "## Search as a tool (Grounding)\n",
        "\n",
        "[Grounding](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/ground-gemini) lets you connect real-world data to the Gemini model.\n",
        "\n",
        "By grounding model responses in Google Search results, the model can access information at runtime that goes beyond its training data which can produce more accurate, up-to-date, and relevant responses.\n",
        "\n",
        "Using Grounding with Google Search, you can improve the accuracy and recency of responses from the model. Starting with Gemini 2.0, Google Search is available as a tool. This means that the model can decide when to use Google Search.\n",
        "\n",
        "For more examples of Grounding, refer to [this notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/grounding/intro-grounding-gemini.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_M_4RRBdO_3"
      },
      "source": [
        "### Google Search\n",
        "\n",
        "You can add the `tools` keyword argument with a `Tool` including `GoogleSearch` to instruct Gemini to first perform a Google Search with the prompt, then construct an answer based on the web search results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "yeR09J3AZT4U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fe9031fe-dc0d-4f7e-80f5-570c815339e7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The current temperature in Austin, TX is 79°F (26°C). The weather is partly cloudy, and it feels like 85°F (29°C) with humidity at around 84%.\n\nThe forecast for the rest of Friday includes scattered thunderstorms during the day with a high of 96°F (36°C) and clear to partly cloudy skies at night with a low of 75°F (24°C). There is a 50% chance of rain during the day and a 45% chance at night."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "google_maps_widget_context_token=None grounding_chunks=[GroundingChunk(\n",
            "  web=GroundingChunkWeb(\n",
            "    domain='google.com',\n",
            "    title='Weather information for Austin, TX, US',\n",
            "    uri='https://www.google.com/search?q=weather+in+Austin, TX,+US'\n",
            "  )\n",
            "), GroundingChunk(\n",
            "  web=GroundingChunkWeb(\n",
            "    domain='accuweather.com',\n",
            "    title='accuweather.com',\n",
            "    uri='https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEPE2QxsCJ-z5Ln0RtjWrf1ygwAT2sBJWMyQ92f9WzzsxG5sG4zZptwB6yR_ePOQBr4ACljXlstpHpOGsKIvGge4DcOO-eHeMAvI9y1ueMVTY851CEF6zVRd12INOVkgsQdzDGR9qR2A6AuvUse34ACHs6obxsNRIxfdpuSRw24oQ=='\n",
            "  )\n",
            ")] grounding_supports=[GroundingSupport(\n",
            "  grounding_chunk_indices=[\n",
            "    0,\n",
            "  ],\n",
            "  segment=Segment(\n",
            "    end_index=55,\n",
            "    text='The current temperature in Austin, TX is 79°F (26°C).'\n",
            "  )\n",
            "), GroundingSupport(\n",
            "  grounding_chunk_indices=[\n",
            "    0,\n",
            "    1,\n",
            "  ],\n",
            "  segment=Segment(\n",
            "    end_index=146,\n",
            "    start_index=56,\n",
            "    text='The weather is partly cloudy, and it feels like 85°F (29°C) with humidity at around 84%.'\n",
            "  )\n",
            "), GroundingSupport(\n",
            "  grounding_chunk_indices=[\n",
            "    0,\n",
            "  ],\n",
            "  segment=Segment(\n",
            "    end_index=331,\n",
            "    start_index=148,\n",
            "    text='The forecast for the rest of Friday includes scattered thunderstorms during the day with a high of 96°F (36°C) and clear to partly cloudy skies at night with a low of 75°F (24°C).'\n",
            "  )\n",
            "), GroundingSupport(\n",
            "  grounding_chunk_indices=[\n",
            "    0,\n",
            "  ],\n",
            "  segment=Segment(\n",
            "    end_index=403,\n",
            "    start_index=332,\n",
            "    text='There is a 50% chance of rain during the day and a 45% chance at night.'\n",
            "  )\n",
            ")] retrieval_metadata=RetrievalMetadata() retrieval_queries=None search_entry_point=SearchEntryPoint(\n",
            "  rendered_content=\"\"\"<style>\n",
            ".container {\n",
            "  align-items: center;\n",
            "  border-radius: 8px;\n",
            "  display: flex;\n",
            "  font-family: Google Sans, Roboto, sans-serif;\n",
            "  font-size: 14px;\n",
            "  line-height: 20px;\n",
            "  padding: 8px 12px;\n",
            "}\n",
            ".chip {\n",
            "  display: inline-block;\n",
            "  border: solid 1px;\n",
            "  border-radius: 16px;\n",
            "  min-width: 14px;\n",
            "  padding: 5px 16px;\n",
            "  text-align: center;\n",
            "  user-select: none;\n",
            "  margin: 0 8px;\n",
            "  -webkit-tap-highlight-color: transparent;\n",
            "}\n",
            ".carousel {\n",
            "  overflow: auto;\n",
            "  scrollbar-width: none;\n",
            "  white-space: nowrap;\n",
            "  margin-right: -12px;\n",
            "}\n",
            ".headline {\n",
            "  display: flex;\n",
            "  margin-right: 4px;\n",
            "}\n",
            ".gradient-container {\n",
            "  position: relative;\n",
            "}\n",
            ".gradient {\n",
            "  position: absolute;\n",
            "  transform: translate(3px, -9px);\n",
            "  height: 36px;\n",
            "  width: 9px;\n",
            "}\n",
            "@media (prefers-color-scheme: light) {\n",
            "  .container {\n",
            "    background-color: #fafafa;\n",
            "    box-shadow: 0 0 0 1px #0000000f;\n",
            "  }\n",
            "  .headline-label {\n",
            "    color: #1f1f1f;\n",
            "  }\n",
            "  .chip {\n",
            "    background-color: #ffffff;\n",
            "    border-color: #d2d2d2;\n",
            "    color: #5e5e5e;\n",
            "    text-decoration: none;\n",
            "  }\n",
            "  .chip:hover {\n",
            "    background-color: #f2f2f2;\n",
            "  }\n",
            "  .chip:focus {\n",
            "    background-color: #f2f2f2;\n",
            "  }\n",
            "  .chip:active {\n",
            "    background-color: #d8d8d8;\n",
            "    border-color: #b6b6b6;\n",
            "  }\n",
            "  .logo-dark {\n",
            "    display: none;\n",
            "  }\n",
            "  .gradient {\n",
            "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
            "  }\n",
            "}\n",
            "@media (prefers-color-scheme: dark) {\n",
            "  .container {\n",
            "    background-color: #1f1f1f;\n",
            "    box-shadow: 0 0 0 1px #ffffff26;\n",
            "  }\n",
            "  .headline-label {\n",
            "    color: #fff;\n",
            "  }\n",
            "  .chip {\n",
            "    background-color: #2c2c2c;\n",
            "    border-color: #3c4043;\n",
            "    color: #fff;\n",
            "    text-decoration: none;\n",
            "  }\n",
            "  .chip:hover {\n",
            "    background-color: #353536;\n",
            "  }\n",
            "  .chip:focus {\n",
            "    background-color: #353536;\n",
            "  }\n",
            "  .chip:active {\n",
            "    background-color: #464849;\n",
            "    border-color: #53575b;\n",
            "  }\n",
            "  .logo-light {\n",
            "    display: none;\n",
            "  }\n",
            "  .gradient {\n",
            "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
            "  }\n",
            "}\n",
            "</style>\n",
            "<div class=\"container\">\n",
            "  <div class=\"headline\">\n",
            "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
            "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
            "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
            "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
            "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
            "    </svg>\n",
            "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
            "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
            "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
            "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
            "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
            "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
            "    </svg>\n",
            "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
            "  </div>\n",
            "  <div class=\"carousel\">\n",
            "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF0BfcGOu41Q-I_Wc6oX2Uct4N4YNOZVeaksFwXuov_MmItiN4jdGdJRBp5dJZBsKi4rHgb9qm-l12zz7mvvSciObK9dLdJCTdfV82gZi52tZp3fzSJYXdC66vVLICcehnwFXz0RtqnCaQO9UR8G6_UwhoIjJIW-06aVaWvRqacWeukgLvNBjXVsK7UBmMTqHIXE2ZS9YsCUf-Xs5fCc9bV2QLp-g==\">current temperature in Austin, TX</a>\n",
            "  </div>\n",
            "</div>\n",
            "\"\"\"\n",
            ") web_search_queries=['current temperature in Austin, TX']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              ".container {\n",
              "  align-items: center;\n",
              "  border-radius: 8px;\n",
              "  display: flex;\n",
              "  font-family: Google Sans, Roboto, sans-serif;\n",
              "  font-size: 14px;\n",
              "  line-height: 20px;\n",
              "  padding: 8px 12px;\n",
              "}\n",
              ".chip {\n",
              "  display: inline-block;\n",
              "  border: solid 1px;\n",
              "  border-radius: 16px;\n",
              "  min-width: 14px;\n",
              "  padding: 5px 16px;\n",
              "  text-align: center;\n",
              "  user-select: none;\n",
              "  margin: 0 8px;\n",
              "  -webkit-tap-highlight-color: transparent;\n",
              "}\n",
              ".carousel {\n",
              "  overflow: auto;\n",
              "  scrollbar-width: none;\n",
              "  white-space: nowrap;\n",
              "  margin-right: -12px;\n",
              "}\n",
              ".headline {\n",
              "  display: flex;\n",
              "  margin-right: 4px;\n",
              "}\n",
              ".gradient-container {\n",
              "  position: relative;\n",
              "}\n",
              ".gradient {\n",
              "  position: absolute;\n",
              "  transform: translate(3px, -9px);\n",
              "  height: 36px;\n",
              "  width: 9px;\n",
              "}\n",
              "@media (prefers-color-scheme: light) {\n",
              "  .container {\n",
              "    background-color: #fafafa;\n",
              "    box-shadow: 0 0 0 1px #0000000f;\n",
              "  }\n",
              "  .headline-label {\n",
              "    color: #1f1f1f;\n",
              "  }\n",
              "  .chip {\n",
              "    background-color: #ffffff;\n",
              "    border-color: #d2d2d2;\n",
              "    color: #5e5e5e;\n",
              "    text-decoration: none;\n",
              "  }\n",
              "  .chip:hover {\n",
              "    background-color: #f2f2f2;\n",
              "  }\n",
              "  .chip:focus {\n",
              "    background-color: #f2f2f2;\n",
              "  }\n",
              "  .chip:active {\n",
              "    background-color: #d8d8d8;\n",
              "    border-color: #b6b6b6;\n",
              "  }\n",
              "  .logo-dark {\n",
              "    display: none;\n",
              "  }\n",
              "  .gradient {\n",
              "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
              "  }\n",
              "}\n",
              "@media (prefers-color-scheme: dark) {\n",
              "  .container {\n",
              "    background-color: #1f1f1f;\n",
              "    box-shadow: 0 0 0 1px #ffffff26;\n",
              "  }\n",
              "  .headline-label {\n",
              "    color: #fff;\n",
              "  }\n",
              "  .chip {\n",
              "    background-color: #2c2c2c;\n",
              "    border-color: #3c4043;\n",
              "    color: #fff;\n",
              "    text-decoration: none;\n",
              "  }\n",
              "  .chip:hover {\n",
              "    background-color: #353536;\n",
              "  }\n",
              "  .chip:focus {\n",
              "    background-color: #353536;\n",
              "  }\n",
              "  .chip:active {\n",
              "    background-color: #464849;\n",
              "    border-color: #53575b;\n",
              "  }\n",
              "  .logo-light {\n",
              "    display: none;\n",
              "  }\n",
              "  .gradient {\n",
              "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
              "  }\n",
              "}\n",
              "</style>\n",
              "<div class=\"container\">\n",
              "  <div class=\"headline\">\n",
              "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
              "    </svg>\n",
              "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
              "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
              "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
              "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
              "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
              "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
              "    </svg>\n",
              "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
              "  </div>\n",
              "  <div class=\"carousel\">\n",
              "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF0BfcGOu41Q-I_Wc6oX2Uct4N4YNOZVeaksFwXuov_MmItiN4jdGdJRBp5dJZBsKi4rHgb9qm-l12zz7mvvSciObK9dLdJCTdfV82gZi52tZp3fzSJYXdC66vVLICcehnwFXz0RtqnCaQO9UR8G6_UwhoIjJIW-06aVaWvRqacWeukgLvNBjXVsK7UBmMTqHIXE2ZS9YsCUf-Xs5fCc9bV2QLp-g==\">current temperature in Austin, TX</a>\n",
              "  </div>\n",
              "</div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "google_search_tool = Tool(google_search=GoogleSearch())\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"What is the current temperature in Austin, TX?\",\n",
        "    config=GenerateContentConfig(\n",
        "        tools=[google_search_tool],\n",
        "        thinking_config=thinking_config,\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))\n",
        "\n",
        "print(response.candidates[0].grounding_metadata)\n",
        "\n",
        "HTML(response.candidates[0].grounding_metadata.search_entry_point.rendered_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0pb-Kh1xEHU"
      },
      "source": [
        "## Function calling\n",
        "\n",
        "[Function Calling](https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/function-calling) in Gemini lets developers create a description of a function in their code, then pass that description to a language model in a request.\n",
        "\n",
        "You can submit a Python function for automatic function calling, which will run the function and return the output in natural language generated by Gemini.\n",
        "\n",
        "You can also submit an [OpenAPI Specification](https://www.openapis.org/) which will respond with the name of a function that matches the description and the arguments to call it with.\n",
        "\n",
        "For more examples of Function calling with Gemini, check out this notebook: [Intro to Function Calling with Gemini](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/function-calling/intro_function_calling.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSUWWlrrlR-D"
      },
      "source": [
        "### Python Function (Automatic Function Calling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "aRR8HZhLlR-E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "outputId": "b23d3280-b466-4c3f-b786-c6d3dcac75f2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The weather in San Francisco is foggy.\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def get_current_weather(location: str) -> str:\n",
        "    \"\"\"Example method. Returns the current weather.\n",
        "\n",
        "    Args:\n",
        "        location: The city and state, e.g. San Francisco, CA\n",
        "    \"\"\"\n",
        "    weather_map: dict[str, str] = {\n",
        "        \"Boston, MA\": \"snowing\",\n",
        "        \"San Francisco, CA\": \"foggy\",\n",
        "        \"Seattle, WA\": \"raining\",\n",
        "        \"Austin, TX\": \"hot\",\n",
        "        \"Chicago, IL\": \"windy\",\n",
        "    }\n",
        "    return weather_map.get(location, \"unknown\")\n",
        "\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"What is the weather like in San Francisco?\",\n",
        "    config=GenerateContentConfig(\n",
        "        tools=[get_current_weather],\n",
        "        temperature=0,\n",
        "        thinking_config=thinking_config,\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4syyLEClGcn"
      },
      "source": [
        "### OpenAPI Specification (Manual Function Calling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "2BDQPwgcxRN3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9deb665-61c0-48b9-8cd4-50f086800796"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id=None args={'destination': 'Paris'} name='get_destination'\n"
          ]
        }
      ],
      "source": [
        "get_destination = FunctionDeclaration(\n",
        "    name=\"get_destination\",\n",
        "    description=\"Get the destination that the user wants to go to\",\n",
        "    parameters={\n",
        "        \"type\": \"OBJECT\",\n",
        "        \"properties\": {\n",
        "            \"destination\": {\n",
        "                \"type\": \"STRING\",\n",
        "                \"description\": \"Destination that the user wants to go to\",\n",
        "            },\n",
        "        },\n",
        "    },\n",
        ")\n",
        "\n",
        "destination_tool = Tool(\n",
        "    function_declarations=[get_destination],\n",
        ")\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"I'd like to travel to Paris.\",\n",
        "    config=GenerateContentConfig(\n",
        "        tools=[destination_tool],\n",
        "        temperature=0,\n",
        "        thinking_config=thinking_config,\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(response.function_calls[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhDs2X3o0neK"
      },
      "source": [
        "## Code Execution\n",
        "\n",
        "The Gemini API [code execution](https://ai.google.dev/gemini-api/docs/code-execution?lang=python) feature enables the model to generate and run Python code and learn iteratively from the results until it arrives at a final output. You can use this code execution capability to build applications that benefit from code-based reasoning and that produce text output. For example, you could use code execution in an application that solves equations or processes text.\n",
        "\n",
        "The Gemini API provides code execution as a tool, similar to function calling.\n",
        "After you add code execution as a tool, the model decides when to use it.\n",
        "\n",
        "For more examples of Code Execution, refer to [this notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/code-execution/intro_code_execution.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "1W-3c7sy0nyz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "83b50f97-a311-4ee4-b49f-6f11ece92a71"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n## Code\n\n```py\ndef fibonacci(n):\n    \"\"\"Calculates the nth Fibonacci number.\"\"\"\n    if n <= 0:\n        return 0\n    elif n == 1:\n        return 1\n    a, b = 0, 1\n    for _ in range(2, n + 1):\n        a, b = b, a + b\n    return b\n\nfib_20 = fibonacci(20)\nprint(f\"The 20th Fibonacci number is: {fib_20}\")\n\n```\n\n### Output\n\n```\nThe 20th Fibonacci number is: 6765\n\n```\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "code_execution_tool = Tool(code_execution=ToolCodeExecution())\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"Calculate 20th fibonacci number. Then find the nearest palindrome to it.\",\n",
        "    config=GenerateContentConfig(\n",
        "        tools=[code_execution_tool],\n",
        "        temperature=0,\n",
        "        thinking_config=thinking_config,\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(\n",
        "    Markdown(\n",
        "        f\"\"\"\n",
        "## Code\n",
        "\n",
        "```py\n",
        "{response.executable_code}\n",
        "```\n",
        "\n",
        "### Output\n",
        "\n",
        "```\n",
        "{response.code_execution_result}\n",
        "```\n",
        "\"\"\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQwiONFdVHw5"
      },
      "source": [
        "## What's next\n",
        "\n",
        "- See the [Google Gen AI SDK reference docs](https://googleapis.github.io/python-genai/).\n",
        "- Explore other notebooks in the [Google Cloud Generative AI GitHub repository](https://github.com/GoogleCloudPlatform/generative-ai).\n",
        "- Explore AI models in [Model Garden](https://cloud.google.com/vertex-ai/generative-ai/docs/model-garden/explore-models)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "intro_gemini_2_5_pro.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}